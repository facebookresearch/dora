<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>dora.shep API documentation</title>
<meta name="description" content="Scheduling and job monitoring utilities." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dora.shep</code></h1>
</header>
<section id="section-intro">
<p>Scheduling and job monitoring utilities.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># Copyright (c) Facebook, Inc. and its affiliates.
# All rights reserved.
#
# This source code is licensed under the license found in the
# LICENSE file in the root directory of this source tree.

&#34;&#34;&#34;Scheduling and job monitoring utilities.
&#34;&#34;&#34;
from contextlib import contextmanager, ExitStack
from dataclasses import dataclass, field
import logging
from pathlib import Path
import pickle
import os
import subprocess as sp
import sys
import typing as tp


from submitit import SlurmJob
import submitit

from . import git_save
from .conf import SlurmConfig, SubmitRules
from .main import DecoratedMain
from .utils import try_load
from .xp import XP, _get_sig, get_xp


logger = logging.getLogger(__name__)


PreemptionCallback = tp.Callable[[], None]
_preemption_callbacks: tp.List[PreemptionCallback] = []


def register_preemption_callaback(callback: PreemptionCallback):
    _preemption_callbacks.append(callback)


class _SubmitItTarget:
    def __call__(self, main: DecoratedMain, argv: tp.Sequence[str], requeue: bool = True):
        from .distrib import get_distrib_spec  # this will import torch which can be quite slow.
        self.requeue = requeue
        spec = get_distrib_spec()
        # We export the RANK as it can be used to customize logging early on
        # in the called program (e.g. using Hydra).
        os.environ[&#39;RANK&#39;] = str(spec.rank)
        sys.argv[1:] = argv
        main()

    def checkpoint(self, *args, **kwargs):
        from .distrib import get_distrib_spec  # this will import torch which can be quite slow.
        for callback in _preemption_callbacks:
            callback()

        if not self.requeue:
            sys.exit(1)  # let&#39;s exit early!

        if get_distrib_spec().rank == 0:
            # cleanup rendezvous file on requeue, otherwise things will fail.
            xp = get_xp()
            if xp.rendezvous_file.exists():
                xp.rendezvous_file.unlink()
        return submitit.helpers.DelayedSubmission(self, *args, **kwargs)


class Sheep:
    &#34;&#34;&#34;
    A Sheep is a specific run for a given XP. Sheeps are managed
    by the Shepherd.
    &#34;&#34;&#34;
    def __init__(self, xp: XP):
        self.xp = xp
        self.job: tp.Optional[submitit.SlurmJob] = None
        # Other jobs contain the list of other jobs in the array
        self._other_jobs: tp.List[submitit.SlurmJob] = []
        self._dependent_jobs: tp.List[submitit.SlurmJob] = []
        if self._job_file.exists():
            content = try_load(self._job_file)
            if isinstance(content, tuple):
                if len(content) == 2:
                    self.job, self._other_jobs = content
                elif len(content) == 3:
                    self.job, self._other_jobs, self._dependent_jobs = content
                else:
                    raise RuntimeError(&#34;Invalid content for job file.&#34;)
            else:
                self.job = content

    @property
    def _job_file(self) -&gt; Path:
        return self.xp.folder / self.xp.dora.shep.job_file

    @staticmethod
    def _get_state(job, other_jobs=[], mode=&#34;standard&#34;):
        &#34;&#34;&#34;Return the current state of the `Sheep`.
        &#34;&#34;&#34;
        if job is None:
            return None
        state = job.watcher.get_state(job.job_id, mode)
        if state == &#39;UNKNOWN&#39; and other_jobs:
            if any(job.state != &#39;UNKNOWN&#39; for job in other_jobs):
                # When cancelling single entries in a job array,
                # sacct will just completely forget about it insted of marking
                # it as cancelled. So we use a specific &#39;MISSING&#39; status to handle that.
                state = &#39;MISSING&#39;
        if state.startswith(&#39;CANCELLED&#39;):
            return &#39;CANCELLED&#39;
        return state

    @staticmethod
    def _is_done(job, mode=&#34;standard&#34;):
        &#34;&#34;&#34;Return True if the job is no longer running on the cluster.
        &#34;&#34;&#34;
        if job is None:
            return True
        return job.watcher.is_done(job.job_id, mode)

    def is_done(self, mode=&#34;standard&#34;):
        &#34;&#34;&#34;Return True if the job is no longer running on the cluster.
        &#34;&#34;&#34;
        if self.job is None:
            return True
        if self._dependent_jobs:
            assert len(self._other_jobs) &lt;= 1
            chain = [self.job] + self._dependent_jobs
            for job in chain:
                if not job.watcher.is_done(job.job_id, mode):
                    return False
            return True
        else:
            return self.job.watcher.is_done(self.job.job_id, mode)

    def state(self, mode=&#34;standard&#34;):
        if self._dependent_jobs:
            assert self.job is not None
            assert len(self._other_jobs) &lt;= 1
            chain = [self.job] + self._dependent_jobs
            for job in chain:
                state = Sheep._get_state(job, [], mode)
                if state == &#39;COMPLETED&#39; or not Sheep._is_done(job, mode):
                    return state
            return state
        else:
            return self._get_state(self.job, self._other_jobs, mode)

    def _log(self, job_id: str) -&gt; Path:
        return self.xp.submitit / f&#34;{job_id}_0_log.out&#34;

    @property
    def current_job_id(self) -&gt; tp.Optional[str]:
        &#34;&#34;&#34;Return the current job id, especially useful when using dependent jobs.
        &#34;&#34;&#34;
        if self.job is None:
            return None
        job_id = self.job.job_id
        # We use the logs to be low tech and not require SLURM.
        for job in self._dependent_jobs:
            if self._log(job.job_id).exists():
                job_id = job.job_id
        return job_id

    @property
    def log(self):
        &#34;&#34;&#34;Return the path to the main log.
        &#34;&#34;&#34;
        if self.job is None:
            return None
        return self._log(self.current_job_id)

    def __repr__(self):
        out = f&#34;Sheep({self.xp.sig}, state={self.state()}, &#34;
        if self.job is not None:
            out += f&#34;sid={self.current_job_id}, &#34;
        out += f&#34;argv={self.xp.argv})&#34;
        return out


def no_log(x: str):
    &#34;&#34;&#34;No logging logging function, passed to `Shepherd`.
    &#34;&#34;&#34;
    pass


@dataclass
class _JobArray:
    slurm_config: SlurmConfig
    sheeps: tp.List[Sheep] = field(default_factory=list)


class Shepherd:
    &#34;&#34;&#34;
    Takes care of the little jobs.

    Args:
        main (DecoratedMain): main function decorated by Dora.
        log (callable): log function, if provided should take a single string
            argument.
    &#34;&#34;&#34;
    def __init__(self, main: DecoratedMain, log: tp.Callable[[str], None] = no_log):
        self.main = main
        self._by_id.mkdir(exist_ok=True, parents=True)
        self._orphans.mkdir(exist_ok=True, parents=True)
        self._arrays.mkdir(exist_ok=True, parents=True)
        self.log = log

        self._in_job_array: bool = False
        self._existing_git_clone: tp.Optional[Path] = None
        self._to_cancel: tp.List[submitit.SlurmJob] = []
        self._to_submit: tp.List[_JobArray] = []

        self._check_orphans()

    def get_sheep_from_argv(self, argv: tp.Sequence[str]) -&gt; Sheep:
        &#34;&#34;&#34;
        Given a list of of arguments, return the matching `Sheep`,
        which will contain both information on the `dora.xp.XP`, and on
        the latest job associated with that XP.
        &#34;&#34;&#34;
        assert not isinstance(argv, str)
        xp = self.main.get_xp(argv)
        return Sheep(xp)

    def get_sheep_from_sig(self, sig: str) -&gt; tp.Optional[Sheep]:
        &#34;&#34;&#34;
        Returns a `Sheep` given the XP signature, if any exists, otherwise
        returns None.
        &#34;&#34;&#34;
        xp = self.main.get_xp_from_sig(sig)
        return Sheep(xp)

    def get_sheep_from_job_id(self, job_id: str) -&gt; tp.Optional[Sheep]:
        &#34;&#34;&#34;
        Returns the `Sheep` associated with the given `job_id`. If no sheep
        is found, returns None.
        &#34;&#34;&#34;
        link = self._by_id / job_id
        if link.is_symlink():
            sig = link.resolve().name
            xp = self.main.get_xp_from_sig(sig)
            return Sheep(xp)
        return None

    def update(self):
        &#34;&#34;&#34;
        Force an update of all job states with submitit.
        &#34;&#34;&#34;
        SlurmJob.watcher.update()

    @contextmanager
    def job_array(self, slurm_config: SlurmConfig):
        &#34;&#34;&#34;Context manager to launch XP in job array.&#34;&#34;&#34;
        assert not self._in_job_array
        self._to_submit.append(_JobArray(slurm_config))
        self._in_job_array = True
        try:
            yield
        finally:
            self._in_job_array = False

    def maybe_submit_lazy(self, sheep: Sheep, slurm_config: SlurmConfig, rules: SubmitRules):
        &#34;&#34;&#34;
        Decides whether to schedule a new job for the given sheep, based on the rules
        given in `rules`.
        Jobs are actually only scheduled once the `commit()` method is called.
        &#34;&#34;&#34;
        if sheep.job is not None:
            state = sheep.state()
            if state == &#39;COMPLETED&#39;:
                if rules.replace_done:
                    logger.debug(f&#34;Ignoring previously completed job {sheep.job.job_id}&#34;)
                    sheep.job = None
            elif state in [&#34;FAILED&#34;, &#34;CANCELLED&#34;, &#34;OUT_OF_MEMORY&#34;, &#34;TIMEOUT&#34;, &#34;MISSING&#34;,
                           &#34;NODE_FAIL&#34;]:
                logger.debug(f&#34;Previous job {sheep.job.job_id} failed or was canceled&#34;)
                if rules.retry:
                    sheep.job = None
            else:
                if rules.replace:
                    logger.debug(f&#34;Cancelling previous job {sheep.job.job_id} with status {state}&#34;)
                    self.cancel_lazy(sheep=sheep)
                    sheep.job = None

        if sheep.job is None:
            if not self._in_job_array:
                self._to_submit.append(_JobArray(slurm_config))
            assert slurm_config == self._to_submit[-1].slurm_config
            self._to_submit[-1].sheeps.append(sheep)

    def cancel_lazy(self, job: tp.Optional[submitit.SlurmJob] = None,
                    dependent_jobs: tp.Sequence[submitit.SlurmJob] = [],
                    sheep: tp.Optional[Sheep] = None):
        &#34;&#34;&#34;
        Cancel a job. The job is actually cancelled only when `commit()` is called.
        You can either provide manually both a job and its dependents, or a sheep that
        will be automatically processed.
        &#34;&#34;&#34;
        if job is None:
            assert sheep is not None
            if sheep.job is not None:
                self._to_cancel += [sheep.job] + list(sheep._dependent_jobs)
        else:
            assert sheep is None
            self._to_cancel += [job] + list(dependent_jobs)

    def commit(self):
        &#34;&#34;&#34;
        Commit all changes registered so far with either `maybe_submit_lazy()`
        and `cancel_lazy()`.
        &#34;&#34;&#34;
        if self._to_cancel:
            self._cancel(self._to_cancel)
            self._to_cancel = []

        self._existing_git_clone = None
        while self._to_submit:
            job_array = self._to_submit.pop(0)
            self._submit(job_array)

    @property
    def _by_id(self) -&gt; Path:
        return self.main.dora.dir / self.main.dora.shep.by_id

    @property
    def _orphans(self) -&gt; Path:
        return self.main.dora.dir / self.main.dora.shep.orphans

    @property
    def _arrays(self) -&gt; Path:
        return self.main.dora.dir / self.main.dora.shep.arrays

    def _cancel(self, jobs: tp.List[SlurmJob]):
        cancel_cmd = [&#34;scancel&#34;] + [job.job_id for job in jobs]
        logger.debug(&#34;Running %s&#34;, &#34; &#34;.join(cancel_cmd))
        sp.run(cancel_cmd, check=True)

    def _get_submitit_executor(self, name: str, folder: Path,
                               slurm_config: SlurmConfig) -&gt; submitit.SlurmExecutor:
        os.environ[&#39;SLURM_KILL_BAD_EXIT&#39;] = &#39;1&#39;  # Kill the job if any of the task fails
        kwargs = dict(slurm_config.__dict__)
        executor = submitit.SlurmExecutor(
            folder=folder, max_num_timeout=kwargs.pop(&#39;max_num_timeout&#39;))
        gpus = slurm_config.gpus
        if gpus &gt; 8:
            if gpus % 8 != 0:
                raise ValueError(&#34;Can only take &lt;= 8 gpus, or multiple of 8 gpus&#34;)
            kwargs[&#39;nodes&#39;] = gpus // 8
            gpus_per_node = 8
        else:
            gpus_per_node = gpus
            kwargs[&#39;nodes&#39;] = 1
        mem_per_gpu = slurm_config.mem_per_gpu
        if mem_per_gpu:
            mem = slurm_config.mem_per_gpu * gpus_per_node
            kwargs[&#39;mem&#39;] = f&#34;{mem}GB&#34;
        kwargs[&#39;gres&#39;] = f&#39;gpu:{gpus_per_node}&#39;
        if slurm_config.one_task_per_node:
            kwargs[&#39;ntasks_per_node&#39;] = 1
            if slurm_config.cpus_per_task is None:
                kwargs[&#39;cpus_per_task&#39;] = gpus_per_node * slurm_config.cpus_per_gpu
        else:
            kwargs[&#39;ntasks_per_node&#39;] = gpus_per_node
            if slurm_config.cpus_per_task is None:
                kwargs[&#39;cpus_per_task&#39;] = slurm_config.cpus_per_gpu
        del kwargs[&#39;gpus&#39;]
        del kwargs[&#39;mem_per_gpu&#39;]
        del kwargs[&#39;cpus_per_gpu&#39;]
        del kwargs[&#39;one_task_per_node&#39;]
        del kwargs[&#39;dependents&#39;]
        logger.debug(&#34;Slurm parameters %r&#34;, kwargs)

        executor.update_parameters(
            job_name=name,
            stderr_to_stdout=True,
            **kwargs)
        return executor

    def _check_orphans(self):
        &#34;&#34;&#34;Check for orphaned jobs.&#34;&#34;&#34;
        for dirty in self._orphans.iterdir():
            name = dirty.name
            logger.warning(f&#34;Found dirty tag {name}, meaning a job might have been scheduled &#34;
                           &#34;but Dora or Slurm crashed before the job id was saved.&#34;)
            proc = sp.run([&#34;squeue&#34;, &#34;-u&#34;, os.getlogin(), &#34;-n&#34;, name, &#34;-o&#34;, &#34;%i&#34;, &#34;-h&#34;],
                          capture_output=True, check=True)
            ids = [line.split(&#39;_&#39;)[0] for line in proc.stdout.decode().strip().split(&#34;\n&#34;) if line]
            if ids:
                logger.warning(f&#34;Found orphan job ids {ids}, will cancel&#34;)
                sp.run([&#34;scancel&#34;] + ids, check=True)
            dirty.unlink()

    @contextmanager
    def _enter_orphan(self, name: str):
        &#34;&#34;&#34;Context manager to enter a potential orphan.&#34;&#34;&#34;
        token = self._orphans / name
        token.touch()
        try:
            yield
        finally:
            token.unlink()

    def _submit(self, job_array: _JobArray):
        sheeps = job_array.sheeps
        slurm_config = job_array.slurm_config
        if not sheeps:
            return

        is_array = len(sheeps) &gt; 1
        first = sheeps[0]
        self.main.init_xp(first.xp)
        use_git_save = first.xp.dora.git_save
        assert all(other.xp.dora.git_save == use_git_save for other in sheeps), \
            &#34;All jobs inside an array must have the same value for git_save.&#34;&#34;&#34;

        requeue = True
        if slurm_config.dependents:
            assert not is_array, &#34;Cannot use dependent jobs and job arrays&#34;
            requeue = False
        if is_array:
            name_sig = _get_sig(sorted([sheep.xp.sig for sheep in sheeps]))
        else:
            name_sig = first.xp.sig
        if is_array:
            name = self.main.name + &#34;_array_&#34; + name_sig
        else:
            name = self.main.name + &#34;_&#34; + name_sig

        if is_array:
            submitit_folder = self._arrays / name
        else:
            submitit_folder = first.xp._xp_submitit
        submitit_folder.mkdir(exist_ok=True)

        for sheep in sheeps:
            xp = sheep.xp
            self.main.init_xp(xp)
            if xp.rendezvous_file.exists():
                xp.rendezvous_file.unlink()

        executor = self._get_submitit_executor(name, submitit_folder, slurm_config)
        jobs: tp.List[submitit.Job] = []
        if use_git_save and self._existing_git_clone is None:
            self._existing_git_clone = git_save.get_new_clone(self.main)
        with self._enter_orphan(name):
            with ExitStack() as stack:
                if use_git_save:
                    assert self._existing_git_clone is not None
                    stack.enter_context(git_save.enter_clone(self._existing_git_clone))
                if is_array:
                    stack.enter_context(executor.batch())
                for sheep in job_array.sheeps:
                    if use_git_save:
                        assert self._existing_git_clone is not None
                        git_save.assign_clone(sheep.xp, self._existing_git_clone)
                    jobs.append(executor.submit(
                        _SubmitItTarget(), self.main, sheep.xp.argv, requeue))
                    if slurm_config.dependents:
                        assert len(job_array.sheeps) == 1
                        for dep_index in range(slurm_config.dependents):
                            requeue = dep_index == slurm_config.dependents - 1
                            last_job_id = jobs[-1].job_id
                            executor.update_parameters(
                                additional_parameters={&#39;dependency&#39;: f&#34;afternotok:{last_job_id}&#34;})
                            jobs.append(executor.submit(
                                _SubmitItTarget(), self.main, sheep.xp.argv, requeue))
            dependent_jobs = []
            if slurm_config.dependents:
                dependent_jobs = jobs[1:]
                jobs = jobs[:1]

            # Now we can access jobs
            for sheep, job in zip(sheeps, jobs):
                # See commment in `Sheep.state` function above for storing all jobs in the array.
                pickle.dump((job, jobs, dependent_jobs), open(sheep._job_file, &#34;wb&#34;))
                logger.debug(&#34;Created job with id %s&#34;, job.job_id)
                sheep.job = job  # type: ignore
                sheep._other_jobs = jobs  # type: ignore
                sheep._dependent_jobs = dependent_jobs  # type: ignore
                link = self._by_id / job.job_id
                link = link
                link.symlink_to(sheep.xp.folder.resolve())
                if is_array:
                    # We link the array submitit folder to be sure
                    # we keep an history of all arrays the XP was in.
                    submitit_link = (sheep.xp.folder / submitit_folder.name)
                    if submitit_link.exists():
                        assert submitit_link.resolve() == submitit_folder.resolve()
                    else:
                        submitit_link.symlink_to(submitit_folder)
                latest = sheep.xp._latest_submitit
                if latest.exists():
                    latest.unlink()
                latest.symlink_to(submitit_folder)

                name = self.main.get_name(sheep.xp)
                self.log(f&#34;Scheduled job {job.job_id} for sheep {sheep.xp.sig}/{name}&#34;)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="dora.shep.no_log"><code class="name flex">
<span>def <span class="ident">no_log</span></span>(<span>x: str)</span>
</code></dt>
<dd>
<div class="desc"><p>No logging logging function, passed to <code><a title="dora.shep.Shepherd" href="#dora.shep.Shepherd">Shepherd</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def no_log(x: str):
    &#34;&#34;&#34;No logging logging function, passed to `Shepherd`.
    &#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
<dt id="dora.shep.register_preemption_callaback"><code class="name flex">
<span>def <span class="ident">register_preemption_callaback</span></span>(<span>callback: Callable[[], None])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def register_preemption_callaback(callback: PreemptionCallback):
    _preemption_callbacks.append(callback)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dora.shep.Sheep"><code class="flex name class">
<span>class <span class="ident">Sheep</span></span>
<span>(</span><span>xp: <a title="dora.xp.XP" href="xp.html#dora.xp.XP">XP</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>A Sheep is a specific run for a given XP. Sheeps are managed
by the Shepherd.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Sheep:
    &#34;&#34;&#34;
    A Sheep is a specific run for a given XP. Sheeps are managed
    by the Shepherd.
    &#34;&#34;&#34;
    def __init__(self, xp: XP):
        self.xp = xp
        self.job: tp.Optional[submitit.SlurmJob] = None
        # Other jobs contain the list of other jobs in the array
        self._other_jobs: tp.List[submitit.SlurmJob] = []
        self._dependent_jobs: tp.List[submitit.SlurmJob] = []
        if self._job_file.exists():
            content = try_load(self._job_file)
            if isinstance(content, tuple):
                if len(content) == 2:
                    self.job, self._other_jobs = content
                elif len(content) == 3:
                    self.job, self._other_jobs, self._dependent_jobs = content
                else:
                    raise RuntimeError(&#34;Invalid content for job file.&#34;)
            else:
                self.job = content

    @property
    def _job_file(self) -&gt; Path:
        return self.xp.folder / self.xp.dora.shep.job_file

    @staticmethod
    def _get_state(job, other_jobs=[], mode=&#34;standard&#34;):
        &#34;&#34;&#34;Return the current state of the `Sheep`.
        &#34;&#34;&#34;
        if job is None:
            return None
        state = job.watcher.get_state(job.job_id, mode)
        if state == &#39;UNKNOWN&#39; and other_jobs:
            if any(job.state != &#39;UNKNOWN&#39; for job in other_jobs):
                # When cancelling single entries in a job array,
                # sacct will just completely forget about it insted of marking
                # it as cancelled. So we use a specific &#39;MISSING&#39; status to handle that.
                state = &#39;MISSING&#39;
        if state.startswith(&#39;CANCELLED&#39;):
            return &#39;CANCELLED&#39;
        return state

    @staticmethod
    def _is_done(job, mode=&#34;standard&#34;):
        &#34;&#34;&#34;Return True if the job is no longer running on the cluster.
        &#34;&#34;&#34;
        if job is None:
            return True
        return job.watcher.is_done(job.job_id, mode)

    def is_done(self, mode=&#34;standard&#34;):
        &#34;&#34;&#34;Return True if the job is no longer running on the cluster.
        &#34;&#34;&#34;
        if self.job is None:
            return True
        if self._dependent_jobs:
            assert len(self._other_jobs) &lt;= 1
            chain = [self.job] + self._dependent_jobs
            for job in chain:
                if not job.watcher.is_done(job.job_id, mode):
                    return False
            return True
        else:
            return self.job.watcher.is_done(self.job.job_id, mode)

    def state(self, mode=&#34;standard&#34;):
        if self._dependent_jobs:
            assert self.job is not None
            assert len(self._other_jobs) &lt;= 1
            chain = [self.job] + self._dependent_jobs
            for job in chain:
                state = Sheep._get_state(job, [], mode)
                if state == &#39;COMPLETED&#39; or not Sheep._is_done(job, mode):
                    return state
            return state
        else:
            return self._get_state(self.job, self._other_jobs, mode)

    def _log(self, job_id: str) -&gt; Path:
        return self.xp.submitit / f&#34;{job_id}_0_log.out&#34;

    @property
    def current_job_id(self) -&gt; tp.Optional[str]:
        &#34;&#34;&#34;Return the current job id, especially useful when using dependent jobs.
        &#34;&#34;&#34;
        if self.job is None:
            return None
        job_id = self.job.job_id
        # We use the logs to be low tech and not require SLURM.
        for job in self._dependent_jobs:
            if self._log(job.job_id).exists():
                job_id = job.job_id
        return job_id

    @property
    def log(self):
        &#34;&#34;&#34;Return the path to the main log.
        &#34;&#34;&#34;
        if self.job is None:
            return None
        return self._log(self.current_job_id)

    def __repr__(self):
        out = f&#34;Sheep({self.xp.sig}, state={self.state()}, &#34;
        if self.job is not None:
            out += f&#34;sid={self.current_job_id}, &#34;
        out += f&#34;argv={self.xp.argv})&#34;
        return out</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="dora.shep.Sheep.current_job_id"><code class="name">var <span class="ident">current_job_id</span> : Optional[str]</code></dt>
<dd>
<div class="desc"><p>Return the current job id, especially useful when using dependent jobs.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def current_job_id(self) -&gt; tp.Optional[str]:
    &#34;&#34;&#34;Return the current job id, especially useful when using dependent jobs.
    &#34;&#34;&#34;
    if self.job is None:
        return None
    job_id = self.job.job_id
    # We use the logs to be low tech and not require SLURM.
    for job in self._dependent_jobs:
        if self._log(job.job_id).exists():
            job_id = job.job_id
    return job_id</code></pre>
</details>
</dd>
<dt id="dora.shep.Sheep.log"><code class="name">var <span class="ident">log</span></code></dt>
<dd>
<div class="desc"><p>Return the path to the main log.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def log(self):
    &#34;&#34;&#34;Return the path to the main log.
    &#34;&#34;&#34;
    if self.job is None:
        return None
    return self._log(self.current_job_id)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dora.shep.Sheep.is_done"><code class="name flex">
<span>def <span class="ident">is_done</span></span>(<span>self, mode='standard')</span>
</code></dt>
<dd>
<div class="desc"><p>Return True if the job is no longer running on the cluster.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_done(self, mode=&#34;standard&#34;):
    &#34;&#34;&#34;Return True if the job is no longer running on the cluster.
    &#34;&#34;&#34;
    if self.job is None:
        return True
    if self._dependent_jobs:
        assert len(self._other_jobs) &lt;= 1
        chain = [self.job] + self._dependent_jobs
        for job in chain:
            if not job.watcher.is_done(job.job_id, mode):
                return False
        return True
    else:
        return self.job.watcher.is_done(self.job.job_id, mode)</code></pre>
</details>
</dd>
<dt id="dora.shep.Sheep.state"><code class="name flex">
<span>def <span class="ident">state</span></span>(<span>self, mode='standard')</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def state(self, mode=&#34;standard&#34;):
    if self._dependent_jobs:
        assert self.job is not None
        assert len(self._other_jobs) &lt;= 1
        chain = [self.job] + self._dependent_jobs
        for job in chain:
            state = Sheep._get_state(job, [], mode)
            if state == &#39;COMPLETED&#39; or not Sheep._is_done(job, mode):
                return state
        return state
    else:
        return self._get_state(self.job, self._other_jobs, mode)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dora.shep.Shepherd"><code class="flex name class">
<span>class <span class="ident">Shepherd</span></span>
<span>(</span><span>main: <a title="dora.main.DecoratedMain" href="main.html#dora.main.DecoratedMain">DecoratedMain</a>, log: Callable[[str], None] = &lt;function no_log&gt;)</span>
</code></dt>
<dd>
<div class="desc"><p>Takes care of the little jobs.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>main</code></strong> :&ensp;<code>DecoratedMain</code></dt>
<dd>main function decorated by Dora.</dd>
<dt><strong><code>log</code></strong> :&ensp;<code>callable</code></dt>
<dd>log function, if provided should take a single string
argument.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Shepherd:
    &#34;&#34;&#34;
    Takes care of the little jobs.

    Args:
        main (DecoratedMain): main function decorated by Dora.
        log (callable): log function, if provided should take a single string
            argument.
    &#34;&#34;&#34;
    def __init__(self, main: DecoratedMain, log: tp.Callable[[str], None] = no_log):
        self.main = main
        self._by_id.mkdir(exist_ok=True, parents=True)
        self._orphans.mkdir(exist_ok=True, parents=True)
        self._arrays.mkdir(exist_ok=True, parents=True)
        self.log = log

        self._in_job_array: bool = False
        self._existing_git_clone: tp.Optional[Path] = None
        self._to_cancel: tp.List[submitit.SlurmJob] = []
        self._to_submit: tp.List[_JobArray] = []

        self._check_orphans()

    def get_sheep_from_argv(self, argv: tp.Sequence[str]) -&gt; Sheep:
        &#34;&#34;&#34;
        Given a list of of arguments, return the matching `Sheep`,
        which will contain both information on the `dora.xp.XP`, and on
        the latest job associated with that XP.
        &#34;&#34;&#34;
        assert not isinstance(argv, str)
        xp = self.main.get_xp(argv)
        return Sheep(xp)

    def get_sheep_from_sig(self, sig: str) -&gt; tp.Optional[Sheep]:
        &#34;&#34;&#34;
        Returns a `Sheep` given the XP signature, if any exists, otherwise
        returns None.
        &#34;&#34;&#34;
        xp = self.main.get_xp_from_sig(sig)
        return Sheep(xp)

    def get_sheep_from_job_id(self, job_id: str) -&gt; tp.Optional[Sheep]:
        &#34;&#34;&#34;
        Returns the `Sheep` associated with the given `job_id`. If no sheep
        is found, returns None.
        &#34;&#34;&#34;
        link = self._by_id / job_id
        if link.is_symlink():
            sig = link.resolve().name
            xp = self.main.get_xp_from_sig(sig)
            return Sheep(xp)
        return None

    def update(self):
        &#34;&#34;&#34;
        Force an update of all job states with submitit.
        &#34;&#34;&#34;
        SlurmJob.watcher.update()

    @contextmanager
    def job_array(self, slurm_config: SlurmConfig):
        &#34;&#34;&#34;Context manager to launch XP in job array.&#34;&#34;&#34;
        assert not self._in_job_array
        self._to_submit.append(_JobArray(slurm_config))
        self._in_job_array = True
        try:
            yield
        finally:
            self._in_job_array = False

    def maybe_submit_lazy(self, sheep: Sheep, slurm_config: SlurmConfig, rules: SubmitRules):
        &#34;&#34;&#34;
        Decides whether to schedule a new job for the given sheep, based on the rules
        given in `rules`.
        Jobs are actually only scheduled once the `commit()` method is called.
        &#34;&#34;&#34;
        if sheep.job is not None:
            state = sheep.state()
            if state == &#39;COMPLETED&#39;:
                if rules.replace_done:
                    logger.debug(f&#34;Ignoring previously completed job {sheep.job.job_id}&#34;)
                    sheep.job = None
            elif state in [&#34;FAILED&#34;, &#34;CANCELLED&#34;, &#34;OUT_OF_MEMORY&#34;, &#34;TIMEOUT&#34;, &#34;MISSING&#34;,
                           &#34;NODE_FAIL&#34;]:
                logger.debug(f&#34;Previous job {sheep.job.job_id} failed or was canceled&#34;)
                if rules.retry:
                    sheep.job = None
            else:
                if rules.replace:
                    logger.debug(f&#34;Cancelling previous job {sheep.job.job_id} with status {state}&#34;)
                    self.cancel_lazy(sheep=sheep)
                    sheep.job = None

        if sheep.job is None:
            if not self._in_job_array:
                self._to_submit.append(_JobArray(slurm_config))
            assert slurm_config == self._to_submit[-1].slurm_config
            self._to_submit[-1].sheeps.append(sheep)

    def cancel_lazy(self, job: tp.Optional[submitit.SlurmJob] = None,
                    dependent_jobs: tp.Sequence[submitit.SlurmJob] = [],
                    sheep: tp.Optional[Sheep] = None):
        &#34;&#34;&#34;
        Cancel a job. The job is actually cancelled only when `commit()` is called.
        You can either provide manually both a job and its dependents, or a sheep that
        will be automatically processed.
        &#34;&#34;&#34;
        if job is None:
            assert sheep is not None
            if sheep.job is not None:
                self._to_cancel += [sheep.job] + list(sheep._dependent_jobs)
        else:
            assert sheep is None
            self._to_cancel += [job] + list(dependent_jobs)

    def commit(self):
        &#34;&#34;&#34;
        Commit all changes registered so far with either `maybe_submit_lazy()`
        and `cancel_lazy()`.
        &#34;&#34;&#34;
        if self._to_cancel:
            self._cancel(self._to_cancel)
            self._to_cancel = []

        self._existing_git_clone = None
        while self._to_submit:
            job_array = self._to_submit.pop(0)
            self._submit(job_array)

    @property
    def _by_id(self) -&gt; Path:
        return self.main.dora.dir / self.main.dora.shep.by_id

    @property
    def _orphans(self) -&gt; Path:
        return self.main.dora.dir / self.main.dora.shep.orphans

    @property
    def _arrays(self) -&gt; Path:
        return self.main.dora.dir / self.main.dora.shep.arrays

    def _cancel(self, jobs: tp.List[SlurmJob]):
        cancel_cmd = [&#34;scancel&#34;] + [job.job_id for job in jobs]
        logger.debug(&#34;Running %s&#34;, &#34; &#34;.join(cancel_cmd))
        sp.run(cancel_cmd, check=True)

    def _get_submitit_executor(self, name: str, folder: Path,
                               slurm_config: SlurmConfig) -&gt; submitit.SlurmExecutor:
        os.environ[&#39;SLURM_KILL_BAD_EXIT&#39;] = &#39;1&#39;  # Kill the job if any of the task fails
        kwargs = dict(slurm_config.__dict__)
        executor = submitit.SlurmExecutor(
            folder=folder, max_num_timeout=kwargs.pop(&#39;max_num_timeout&#39;))
        gpus = slurm_config.gpus
        if gpus &gt; 8:
            if gpus % 8 != 0:
                raise ValueError(&#34;Can only take &lt;= 8 gpus, or multiple of 8 gpus&#34;)
            kwargs[&#39;nodes&#39;] = gpus // 8
            gpus_per_node = 8
        else:
            gpus_per_node = gpus
            kwargs[&#39;nodes&#39;] = 1
        mem_per_gpu = slurm_config.mem_per_gpu
        if mem_per_gpu:
            mem = slurm_config.mem_per_gpu * gpus_per_node
            kwargs[&#39;mem&#39;] = f&#34;{mem}GB&#34;
        kwargs[&#39;gres&#39;] = f&#39;gpu:{gpus_per_node}&#39;
        if slurm_config.one_task_per_node:
            kwargs[&#39;ntasks_per_node&#39;] = 1
            if slurm_config.cpus_per_task is None:
                kwargs[&#39;cpus_per_task&#39;] = gpus_per_node * slurm_config.cpus_per_gpu
        else:
            kwargs[&#39;ntasks_per_node&#39;] = gpus_per_node
            if slurm_config.cpus_per_task is None:
                kwargs[&#39;cpus_per_task&#39;] = slurm_config.cpus_per_gpu
        del kwargs[&#39;gpus&#39;]
        del kwargs[&#39;mem_per_gpu&#39;]
        del kwargs[&#39;cpus_per_gpu&#39;]
        del kwargs[&#39;one_task_per_node&#39;]
        del kwargs[&#39;dependents&#39;]
        logger.debug(&#34;Slurm parameters %r&#34;, kwargs)

        executor.update_parameters(
            job_name=name,
            stderr_to_stdout=True,
            **kwargs)
        return executor

    def _check_orphans(self):
        &#34;&#34;&#34;Check for orphaned jobs.&#34;&#34;&#34;
        for dirty in self._orphans.iterdir():
            name = dirty.name
            logger.warning(f&#34;Found dirty tag {name}, meaning a job might have been scheduled &#34;
                           &#34;but Dora or Slurm crashed before the job id was saved.&#34;)
            proc = sp.run([&#34;squeue&#34;, &#34;-u&#34;, os.getlogin(), &#34;-n&#34;, name, &#34;-o&#34;, &#34;%i&#34;, &#34;-h&#34;],
                          capture_output=True, check=True)
            ids = [line.split(&#39;_&#39;)[0] for line in proc.stdout.decode().strip().split(&#34;\n&#34;) if line]
            if ids:
                logger.warning(f&#34;Found orphan job ids {ids}, will cancel&#34;)
                sp.run([&#34;scancel&#34;] + ids, check=True)
            dirty.unlink()

    @contextmanager
    def _enter_orphan(self, name: str):
        &#34;&#34;&#34;Context manager to enter a potential orphan.&#34;&#34;&#34;
        token = self._orphans / name
        token.touch()
        try:
            yield
        finally:
            token.unlink()

    def _submit(self, job_array: _JobArray):
        sheeps = job_array.sheeps
        slurm_config = job_array.slurm_config
        if not sheeps:
            return

        is_array = len(sheeps) &gt; 1
        first = sheeps[0]
        self.main.init_xp(first.xp)
        use_git_save = first.xp.dora.git_save
        assert all(other.xp.dora.git_save == use_git_save for other in sheeps), \
            &#34;All jobs inside an array must have the same value for git_save.&#34;&#34;&#34;

        requeue = True
        if slurm_config.dependents:
            assert not is_array, &#34;Cannot use dependent jobs and job arrays&#34;
            requeue = False
        if is_array:
            name_sig = _get_sig(sorted([sheep.xp.sig for sheep in sheeps]))
        else:
            name_sig = first.xp.sig
        if is_array:
            name = self.main.name + &#34;_array_&#34; + name_sig
        else:
            name = self.main.name + &#34;_&#34; + name_sig

        if is_array:
            submitit_folder = self._arrays / name
        else:
            submitit_folder = first.xp._xp_submitit
        submitit_folder.mkdir(exist_ok=True)

        for sheep in sheeps:
            xp = sheep.xp
            self.main.init_xp(xp)
            if xp.rendezvous_file.exists():
                xp.rendezvous_file.unlink()

        executor = self._get_submitit_executor(name, submitit_folder, slurm_config)
        jobs: tp.List[submitit.Job] = []
        if use_git_save and self._existing_git_clone is None:
            self._existing_git_clone = git_save.get_new_clone(self.main)
        with self._enter_orphan(name):
            with ExitStack() as stack:
                if use_git_save:
                    assert self._existing_git_clone is not None
                    stack.enter_context(git_save.enter_clone(self._existing_git_clone))
                if is_array:
                    stack.enter_context(executor.batch())
                for sheep in job_array.sheeps:
                    if use_git_save:
                        assert self._existing_git_clone is not None
                        git_save.assign_clone(sheep.xp, self._existing_git_clone)
                    jobs.append(executor.submit(
                        _SubmitItTarget(), self.main, sheep.xp.argv, requeue))
                    if slurm_config.dependents:
                        assert len(job_array.sheeps) == 1
                        for dep_index in range(slurm_config.dependents):
                            requeue = dep_index == slurm_config.dependents - 1
                            last_job_id = jobs[-1].job_id
                            executor.update_parameters(
                                additional_parameters={&#39;dependency&#39;: f&#34;afternotok:{last_job_id}&#34;})
                            jobs.append(executor.submit(
                                _SubmitItTarget(), self.main, sheep.xp.argv, requeue))
            dependent_jobs = []
            if slurm_config.dependents:
                dependent_jobs = jobs[1:]
                jobs = jobs[:1]

            # Now we can access jobs
            for sheep, job in zip(sheeps, jobs):
                # See commment in `Sheep.state` function above for storing all jobs in the array.
                pickle.dump((job, jobs, dependent_jobs), open(sheep._job_file, &#34;wb&#34;))
                logger.debug(&#34;Created job with id %s&#34;, job.job_id)
                sheep.job = job  # type: ignore
                sheep._other_jobs = jobs  # type: ignore
                sheep._dependent_jobs = dependent_jobs  # type: ignore
                link = self._by_id / job.job_id
                link = link
                link.symlink_to(sheep.xp.folder.resolve())
                if is_array:
                    # We link the array submitit folder to be sure
                    # we keep an history of all arrays the XP was in.
                    submitit_link = (sheep.xp.folder / submitit_folder.name)
                    if submitit_link.exists():
                        assert submitit_link.resolve() == submitit_folder.resolve()
                    else:
                        submitit_link.symlink_to(submitit_folder)
                latest = sheep.xp._latest_submitit
                if latest.exists():
                    latest.unlink()
                latest.symlink_to(submitit_folder)

                name = self.main.get_name(sheep.xp)
                self.log(f&#34;Scheduled job {job.job_id} for sheep {sheep.xp.sig}/{name}&#34;)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="dora.shep.Shepherd.cancel_lazy"><code class="name flex">
<span>def <span class="ident">cancel_lazy</span></span>(<span>self, job: Optional[submitit.slurm.slurm.SlurmJob] = None, dependent_jobs: Sequence[submitit.slurm.slurm.SlurmJob] = [], sheep: Optional[<a title="dora.shep.Sheep" href="#dora.shep.Sheep">Sheep</a>] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Cancel a job. The job is actually cancelled only when <code>commit()</code> is called.
You can either provide manually both a job and its dependents, or a sheep that
will be automatically processed.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cancel_lazy(self, job: tp.Optional[submitit.SlurmJob] = None,
                dependent_jobs: tp.Sequence[submitit.SlurmJob] = [],
                sheep: tp.Optional[Sheep] = None):
    &#34;&#34;&#34;
    Cancel a job. The job is actually cancelled only when `commit()` is called.
    You can either provide manually both a job and its dependents, or a sheep that
    will be automatically processed.
    &#34;&#34;&#34;
    if job is None:
        assert sheep is not None
        if sheep.job is not None:
            self._to_cancel += [sheep.job] + list(sheep._dependent_jobs)
    else:
        assert sheep is None
        self._to_cancel += [job] + list(dependent_jobs)</code></pre>
</details>
</dd>
<dt id="dora.shep.Shepherd.commit"><code class="name flex">
<span>def <span class="ident">commit</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Commit all changes registered so far with either <code>maybe_submit_lazy()</code>
and <code>cancel_lazy()</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def commit(self):
    &#34;&#34;&#34;
    Commit all changes registered so far with either `maybe_submit_lazy()`
    and `cancel_lazy()`.
    &#34;&#34;&#34;
    if self._to_cancel:
        self._cancel(self._to_cancel)
        self._to_cancel = []

    self._existing_git_clone = None
    while self._to_submit:
        job_array = self._to_submit.pop(0)
        self._submit(job_array)</code></pre>
</details>
</dd>
<dt id="dora.shep.Shepherd.get_sheep_from_argv"><code class="name flex">
<span>def <span class="ident">get_sheep_from_argv</span></span>(<span>self, argv: Sequence[str]) ‑> <a title="dora.shep.Sheep" href="#dora.shep.Sheep">Sheep</a></span>
</code></dt>
<dd>
<div class="desc"><p>Given a list of of arguments, return the matching <code><a title="dora.shep.Sheep" href="#dora.shep.Sheep">Sheep</a></code>,
which will contain both information on the <code><a title="dora.xp.XP" href="xp.html#dora.xp.XP">XP</a></code>, and on
the latest job associated with that XP.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_sheep_from_argv(self, argv: tp.Sequence[str]) -&gt; Sheep:
    &#34;&#34;&#34;
    Given a list of of arguments, return the matching `Sheep`,
    which will contain both information on the `dora.xp.XP`, and on
    the latest job associated with that XP.
    &#34;&#34;&#34;
    assert not isinstance(argv, str)
    xp = self.main.get_xp(argv)
    return Sheep(xp)</code></pre>
</details>
</dd>
<dt id="dora.shep.Shepherd.get_sheep_from_job_id"><code class="name flex">
<span>def <span class="ident">get_sheep_from_job_id</span></span>(<span>self, job_id: str) ‑> Optional[<a title="dora.shep.Sheep" href="#dora.shep.Sheep">Sheep</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the <code><a title="dora.shep.Sheep" href="#dora.shep.Sheep">Sheep</a></code> associated with the given <code>job_id</code>. If no sheep
is found, returns None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_sheep_from_job_id(self, job_id: str) -&gt; tp.Optional[Sheep]:
    &#34;&#34;&#34;
    Returns the `Sheep` associated with the given `job_id`. If no sheep
    is found, returns None.
    &#34;&#34;&#34;
    link = self._by_id / job_id
    if link.is_symlink():
        sig = link.resolve().name
        xp = self.main.get_xp_from_sig(sig)
        return Sheep(xp)
    return None</code></pre>
</details>
</dd>
<dt id="dora.shep.Shepherd.get_sheep_from_sig"><code class="name flex">
<span>def <span class="ident">get_sheep_from_sig</span></span>(<span>self, sig: str) ‑> Optional[<a title="dora.shep.Sheep" href="#dora.shep.Sheep">Sheep</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a <code><a title="dora.shep.Sheep" href="#dora.shep.Sheep">Sheep</a></code> given the XP signature, if any exists, otherwise
returns None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_sheep_from_sig(self, sig: str) -&gt; tp.Optional[Sheep]:
    &#34;&#34;&#34;
    Returns a `Sheep` given the XP signature, if any exists, otherwise
    returns None.
    &#34;&#34;&#34;
    xp = self.main.get_xp_from_sig(sig)
    return Sheep(xp)</code></pre>
</details>
</dd>
<dt id="dora.shep.Shepherd.job_array"><code class="name flex">
<span>def <span class="ident">job_array</span></span>(<span>self, slurm_config: <a title="dora.conf.SlurmConfig" href="conf.html#dora.conf.SlurmConfig">SlurmConfig</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Context manager to launch XP in job array.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@contextmanager
def job_array(self, slurm_config: SlurmConfig):
    &#34;&#34;&#34;Context manager to launch XP in job array.&#34;&#34;&#34;
    assert not self._in_job_array
    self._to_submit.append(_JobArray(slurm_config))
    self._in_job_array = True
    try:
        yield
    finally:
        self._in_job_array = False</code></pre>
</details>
</dd>
<dt id="dora.shep.Shepherd.maybe_submit_lazy"><code class="name flex">
<span>def <span class="ident">maybe_submit_lazy</span></span>(<span>self, sheep: <a title="dora.shep.Sheep" href="#dora.shep.Sheep">Sheep</a>, slurm_config: <a title="dora.conf.SlurmConfig" href="conf.html#dora.conf.SlurmConfig">SlurmConfig</a>, rules: <a title="dora.conf.SubmitRules" href="conf.html#dora.conf.SubmitRules">SubmitRules</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Decides whether to schedule a new job for the given sheep, based on the rules
given in <code>rules</code>.
Jobs are actually only scheduled once the <code>commit()</code> method is called.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def maybe_submit_lazy(self, sheep: Sheep, slurm_config: SlurmConfig, rules: SubmitRules):
    &#34;&#34;&#34;
    Decides whether to schedule a new job for the given sheep, based on the rules
    given in `rules`.
    Jobs are actually only scheduled once the `commit()` method is called.
    &#34;&#34;&#34;
    if sheep.job is not None:
        state = sheep.state()
        if state == &#39;COMPLETED&#39;:
            if rules.replace_done:
                logger.debug(f&#34;Ignoring previously completed job {sheep.job.job_id}&#34;)
                sheep.job = None
        elif state in [&#34;FAILED&#34;, &#34;CANCELLED&#34;, &#34;OUT_OF_MEMORY&#34;, &#34;TIMEOUT&#34;, &#34;MISSING&#34;,
                       &#34;NODE_FAIL&#34;]:
            logger.debug(f&#34;Previous job {sheep.job.job_id} failed or was canceled&#34;)
            if rules.retry:
                sheep.job = None
        else:
            if rules.replace:
                logger.debug(f&#34;Cancelling previous job {sheep.job.job_id} with status {state}&#34;)
                self.cancel_lazy(sheep=sheep)
                sheep.job = None

    if sheep.job is None:
        if not self._in_job_array:
            self._to_submit.append(_JobArray(slurm_config))
        assert slurm_config == self._to_submit[-1].slurm_config
        self._to_submit[-1].sheeps.append(sheep)</code></pre>
</details>
</dd>
<dt id="dora.shep.Shepherd.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Force an update of all job states with submitit.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update(self):
    &#34;&#34;&#34;
    Force an update of all job states with submitit.
    &#34;&#34;&#34;
    SlurmJob.watcher.update()</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dora" href="index.html">dora</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="dora.shep.no_log" href="#dora.shep.no_log">no_log</a></code></li>
<li><code><a title="dora.shep.register_preemption_callaback" href="#dora.shep.register_preemption_callaback">register_preemption_callaback</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dora.shep.Sheep" href="#dora.shep.Sheep">Sheep</a></code></h4>
<ul class="">
<li><code><a title="dora.shep.Sheep.current_job_id" href="#dora.shep.Sheep.current_job_id">current_job_id</a></code></li>
<li><code><a title="dora.shep.Sheep.is_done" href="#dora.shep.Sheep.is_done">is_done</a></code></li>
<li><code><a title="dora.shep.Sheep.log" href="#dora.shep.Sheep.log">log</a></code></li>
<li><code><a title="dora.shep.Sheep.state" href="#dora.shep.Sheep.state">state</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dora.shep.Shepherd" href="#dora.shep.Shepherd">Shepherd</a></code></h4>
<ul class="">
<li><code><a title="dora.shep.Shepherd.cancel_lazy" href="#dora.shep.Shepherd.cancel_lazy">cancel_lazy</a></code></li>
<li><code><a title="dora.shep.Shepherd.commit" href="#dora.shep.Shepherd.commit">commit</a></code></li>
<li><code><a title="dora.shep.Shepherd.get_sheep_from_argv" href="#dora.shep.Shepherd.get_sheep_from_argv">get_sheep_from_argv</a></code></li>
<li><code><a title="dora.shep.Shepherd.get_sheep_from_job_id" href="#dora.shep.Shepherd.get_sheep_from_job_id">get_sheep_from_job_id</a></code></li>
<li><code><a title="dora.shep.Shepherd.get_sheep_from_sig" href="#dora.shep.Shepherd.get_sheep_from_sig">get_sheep_from_sig</a></code></li>
<li><code><a title="dora.shep.Shepherd.job_array" href="#dora.shep.Shepherd.job_array">job_array</a></code></li>
<li><code><a title="dora.shep.Shepherd.maybe_submit_lazy" href="#dora.shep.Shepherd.maybe_submit_lazy">maybe_submit_lazy</a></code></li>
<li><code><a title="dora.shep.Shepherd.update" href="#dora.shep.Shepherd.update">update</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>